{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e93c614",
   "metadata": {},
   "source": [
    "# (Legacy) xgboost_CVGrid.ipynb\n",
    "\n",
    "XGBoost baseline + time-respecting grid search。建议保留作参考，但后续如要系统化对比，最好抽成模块/脚本并统一输出格式。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Fixed-window time-series modeling with XGBoost + Grid Search (Robust) + Last-fold Plot\n",
    "#\n",
    "# This notebook implements a strict fixed-window time-series cross-validation (CV):\n",
    "# - Each fold trains only on the most recent `train_window` observations (e.g., 20 trading days),\n",
    "# - Validates on the next `val_size` days (for early stopping and hyperparameter selection),\n",
    "# - And tests on the subsequent `test_size` days.\n",
    "#\n",
    "# We add a time-respecting Grid Search with robust fallbacks:\n",
    "# - For every outer fold, we run a small grid search using ONLY the contiguous validation window\n",
    "#   (immediately following the training window) to select hyperparameters.\n",
    "# - We handle edge-cases where a window has only one class by safely falling back to balanced accuracy\n",
    "#   and accuracy, and by using constant models when needed.\n",
    "# - We always return a valid model from the grid search (never None) to avoid runtime errors.\n",
    "#\n",
    "# Notes:\n",
    "# - Feature engineering uses ≤ 20-day lookback to match the assumption that the process\n",
    "#   depends only on recent history (~20 days).\n",
    "# - We assume XGBoost is available.\n",
    "# - Default grids are intentionally small to keep runtime reasonable. You can expand them.\n",
    "\n",
    "# %%\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from itertools import product\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid') if 'seaborn-v0_8-whitegrid' in plt.style.available else plt.style.use('ggplot')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "print(\"XGBoost available:\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed54602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Data: 2800.HK, daily, 3 years\n",
    "# Pull adjusted OHLCV data using `yfinance`. If `period` fails, fallback to explicit start/end dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def fetch_prices(ticker: str = \"2800.HK\", period: str = \"3y\", interval: str = \"1d\") -> pd.DataFrame:\n",
    "    \"\"\"Fetch adjusted OHLCV data. Index is timezone-naive DateTimeIndex.\"\"\"\n",
    "    tk = yf.Ticker(ticker)\n",
    "    df = tk.history(period=period, interval=interval, auto_adjust=True)\n",
    "    if df is None or df.empty:\n",
    "        end = pd.Timestamp.today().normalize()\n",
    "        start = end - pd.Timedelta(days=3*370)\n",
    "        df = tk.history(start=start, end=end, interval=interval, auto_adjust=True)\n",
    "    if df is None or df.empty:\n",
    "        raise RuntimeError(f\"Cannot fetch data for {ticker}\")\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    return df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
    "\n",
    "ticker = \"2800.HK\"\n",
    "df_raw = fetch_prices(ticker=ticker, period=\"1y\", interval=\"1d\")\n",
    "print(f\"Data range: {df_raw.index.min().date()} to {df_raw.index.max().date()}\")\n",
    "print(f\"Total samples: {len(df_raw)}\")\n",
    "display(df_raw.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc315d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Feature engineering (max 20-day lookback)\n",
    "# - Use only past information up to and including time t (no leakage).\n",
    "# - Constrain all rolling windows to ≤ 20 trading days to match the “depends only on last 20 days” assumption.\n",
    "# - Labels:\n",
    "#   - Regression: `next_return` = log return from t to t+1 (`use_log_return=True`).\n",
    "#   - Classification: `target_up` = 1 if `next_return` > 0 else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def calculate_rsi_rolling(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    \"\"\"RSI computed with rolling simple means to ensure finite memory.\"\"\"\n",
    "    delta = series.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    roll_up = up.rolling(window=period, min_periods=period).mean()\n",
    "    roll_down = down.rolling(window=period, min_periods=period).mean().replace(0, np.nan)\n",
    "    rs = roll_up / roll_down\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd_sma(close: pd.Series, fast: int = 8, slow: int = 16, signal: int = 6):\n",
    "    \"\"\"MACD variant using simple moving averages (finite lookback).\"\"\"\n",
    "    sma_fast = close.rolling(window=fast, min_periods=fast).mean()\n",
    "    sma_slow = close.rolling(window=slow, min_periods=slow).mean()\n",
    "    macd_line = sma_fast - sma_slow\n",
    "    signal_line = macd_line.rolling(window=signal, min_periods=signal).mean()\n",
    "    histogram = macd_line - signal_line\n",
    "    return macd_line, signal_line, histogram\n",
    "\n",
    "def build_features_and_labels(df: pd.DataFrame,\n",
    "                              horizon: int = 1,\n",
    "                              use_log_return: bool = True,\n",
    "                              max_lookback: int = 20) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"Build features using only up to `max_lookback` days of history.\"\"\"\n",
    "    close = df[\"Close\"].copy()\n",
    "    vol = df[\"Volume\"].copy() if \"Volume\" in df.columns else None\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # Returns up to t\n",
    "    features[\"ret_1d\"] = close.pct_change(1)\n",
    "    features[\"ret_2d\"] = close.pct_change(2)\n",
    "    features[\"ret_5d\"] = close.pct_change(5)\n",
    "    features[\"ret_10d\"] = close.pct_change(10)\n",
    "\n",
    "    # Realized volatility\n",
    "    features[\"vol_5d\"] = features[\"ret_1d\"].rolling(5, min_periods=5).std()\n",
    "    features[\"vol_10d\"] = features[\"ret_1d\"].rolling(10, min_periods=10).std()\n",
    "    features[\"vol_20d\"] = features[\"ret_1d\"].rolling(20, min_periods=20).std()\n",
    "\n",
    "    # Moving averages and relative position\n",
    "    sma_5 = close.rolling(5, min_periods=5).mean()\n",
    "    sma_10 = close.rolling(10, min_periods=10).mean()\n",
    "    sma_20 = close.rolling(20, min_periods=20).mean()\n",
    "\n",
    "    features[\"close_to_sma5\"] = close / sma_5 - 1\n",
    "    features[\"close_to_sma10\"] = close / sma_10 - 1\n",
    "    features[\"close_to_sma20\"] = close / sma_20 - 1\n",
    "    features[\"sma5_sma10\"] = sma_5 / sma_10 - 1\n",
    "    features[\"sma10_sma20\"] = sma_10 / sma_20 - 1\n",
    "\n",
    "    # Technical indicators (≤20-day lookback)\n",
    "    features[\"rsi_14\"] = calculate_rsi_rolling(close, 14)\n",
    "    macd_line, signal_line, histogram = calculate_macd_sma(close, fast=8, slow=16, signal=6)\n",
    "    features[\"macd\"] = macd_line\n",
    "    features[\"macd_signal\"] = signal_line\n",
    "    features[\"macd_hist\"] = histogram\n",
    "\n",
    "    # Bollinger bands (20-day)\n",
    "    bb_period = min(20, max_lookback)\n",
    "    bb_std = close.rolling(bb_period, min_periods=bb_period).std()\n",
    "    bb_mean = close.rolling(bb_period, min_periods=bb_period).mean()\n",
    "    features[\"bb_upper\"] = (bb_mean + 2 * bb_std - close) / close\n",
    "    features[\"bb_lower\"] = (close - (bb_mean - 2 * bb_std)) / close\n",
    "\n",
    "    # Volume features (bounded to 20 days)\n",
    "    if vol is not None:\n",
    "        features[\"volume_ratio\"] = vol / vol.rolling(20, min_periods=20).mean()\n",
    "        features[\"volume_change\"] = vol.pct_change()\n",
    "\n",
    "    # Calendar features\n",
    "    features[\"day_of_week\"] = df.index.dayofweek\n",
    "    features[\"month\"] = df.index.month\n",
    "    features[\"quarter\"] = df.index.quarter\n",
    "\n",
    "    # Lagged returns up to 20 days back\n",
    "    for lag in [1, 2, 3, 5, 10, 15, 20]:\n",
    "        features[f\"ret_lag_{lag}\"] = features[\"ret_1d\"].shift(lag)\n",
    "\n",
    "    # Targets\n",
    "    if use_log_return:\n",
    "        next_ret = np.log(close.shift(-horizon) / close)\n",
    "    else:\n",
    "        next_ret = close.pct_change(horizon).shift(-horizon)\n",
    "    target_up = (next_ret > 0).astype(int)\n",
    "\n",
    "    # Clean and merge\n",
    "    features = features.replace([np.inf, -np.inf], np.nan)\n",
    "    data = features.copy()\n",
    "    data[\"next_return\"] = next_ret\n",
    "    data[\"target_up\"] = target_up\n",
    "    data = data.dropna().copy()\n",
    "\n",
    "    feature_cols = [c for c in data.columns if c not in [\"next_return\", \"target_up\"]]\n",
    "    return data, feature_cols\n",
    "\n",
    "# Build features & labels\n",
    "feat_df, feature_cols = build_features_and_labels(df_raw, horizon=1, use_log_return=True, max_lookback=20)\n",
    "print(f\"Samples after cleaning: {len(feat_df)}, Features: {len(feature_cols)}\")\n",
    "display(feat_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Grid Search helpers (time-respecting, robust to single-class windows)\n",
    "# - Train on training window, evaluate on contiguous validation window.\n",
    "# - Classifier selection: prefer AUC if defined; otherwise fallback to Balanced Accuracy, then Accuracy.\n",
    "# - Regressor selection: lowest RMSE on validation.\n",
    "# - Always return a model (never None). For single-class training, use a constant-probability classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def param_grid_product(param_grid: Dict[str, List[Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Cartesian product of parameter grid.\"\"\"\n",
    "    if not isinstance(param_grid, dict) or len(param_grid) == 0:\n",
    "        return []\n",
    "    keys = list(param_grid.keys())\n",
    "    values = [param_grid[k] for k in keys]\n",
    "    combos = []\n",
    "    for combo in product(*values):\n",
    "        combos.append(dict(zip(keys, combo)))\n",
    "    return combos\n",
    "\n",
    "# Small, time-friendly grids (expand if needed)\n",
    "DEFAULT_GRID_CLS: Dict[str, List[Any]] = {\n",
    "    \"learning_rate\": [0.03, 0.07],\n",
    "    \"max_depth\": [3, 4],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"subsample\": [0.8],           # can try [0.7, 0.9]\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_alpha\": [0.0, 0.5],\n",
    "    \"reg_lambda\": [1.0],          # can try [0.5, 1.0, 2.0]\n",
    "}\n",
    "DEFAULT_GRID_REG: Dict[str, List[Any]] = {\n",
    "    \"learning_rate\": [0.03, 0.07],\n",
    "    \"max_depth\": [3, 4],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_alpha\": [0.0, 0.5],\n",
    "    \"reg_lambda\": [1.0],\n",
    "}\n",
    "\n",
    "BASE_XGB_CLS = dict(\n",
    "    n_estimators=500,\n",
    "    random_state=SEED,\n",
    "    eval_metric=\"logloss\",\n",
    "    verbosity=0,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "BASE_XGB_REG = dict(\n",
    "    n_estimators=500,\n",
    "    random_state=SEED,\n",
    "    eval_metric=\"rmse\",\n",
    "    verbosity=0,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "def is_single_class(y: np.ndarray) -> bool:\n",
    "    \"\"\"Return True if y contains fewer than 2 unique classes.\"\"\"\n",
    "    try:\n",
    "        return np.unique(y).size < 2\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "class ConstantProbaClassifier:\n",
    "    \"\"\"Simple classifier that predicts a constant probability for class 1.\"\"\"\n",
    "    def __init__(self, p: float):\n",
    "        p = float(p)\n",
    "        self.p = float(np.clip(p, 1e-6, 1 - 1e-6))\n",
    "        self.classes_ = np.array([0, 1])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        n = len(X)\n",
    "        p1 = np.full(n, self.p, dtype=float)\n",
    "        p0 = 1.0 - p1\n",
    "        return np.column_stack([p0, p1])\n",
    "\n",
    "class ConstantMeanRegressor:\n",
    "    \"\"\"Regressor that always predicts the training mean.\"\"\"\n",
    "    def __init__(self, mu: float):\n",
    "        self.mu = float(mu)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mu, dtype=float)\n",
    "\n",
    "def fit_xgb_classifier(X_train, y_train, X_val=None, y_val=None, params: Optional[Dict[str, Any]] = None):\n",
    "    \"\"\"Fit XGBClassifier with optional early stopping on a provided validation set.\n",
    "       Falls back to a constant-probability classifier if training labels are single-class.\n",
    "    \"\"\"\n",
    "    if is_single_class(y_train):\n",
    "        return ConstantProbaClassifier(p=float(np.mean(y_train)))\n",
    "\n",
    "    kwargs = BASE_XGB_CLS.copy()\n",
    "    if params:\n",
    "        kwargs.update(params)\n",
    "    clf = XGBClassifier(**kwargs)\n",
    "    if X_val is not None and y_val is not None and len(X_val) > 0:\n",
    "        clf.set_params(early_stopping_rounds=30)\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train, verbose=False)\n",
    "    return clf\n",
    "\n",
    "def fit_xgb_regressor(X_train, y_train, X_val=None, y_val=None, params: Optional[Dict[str, Any]] = None):\n",
    "    \"\"\"Fit XGBRegressor with optional early stopping on a provided validation set.\n",
    "       Falls back to a constant-mean regressor if y_train is degenerate/too small to learn.\n",
    "    \"\"\"\n",
    "    if len(y_train) == 0 or np.nanstd(y_train) == 0:\n",
    "        return ConstantMeanRegressor(mu=float(np.nanmean(y_train) if len(y_train) else 0.0))\n",
    "\n",
    "    kwargs = BASE_XGB_REG.copy()\n",
    "    if params:\n",
    "        kwargs.update(params)\n",
    "    reg = XGBRegressor(**kwargs)\n",
    "    if X_val is not None and y_val is not None and len(X_val) > 0:\n",
    "        reg.set_params(early_stopping_rounds=30)\n",
    "        reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    else:\n",
    "        reg.fit(X_train, y_train, verbose=False)\n",
    "    return reg\n",
    "\n",
    "def safe_classification_score(y_true: np.ndarray, proba: np.ndarray) -> Tuple[float, Dict[str, float]]:\n",
    "    \"\"\"Return a scalar score for model selection and a dict of validation metrics.\n",
    "       Preference: AUC (if defined) -> Balanced Accuracy -> Accuracy.\n",
    "       NaNs are handled robustly.\n",
    "    \"\"\"\n",
    "    metrics: Dict[str, float] = {}\n",
    "    score = -np.inf\n",
    "\n",
    "    # Try AUC if both classes present\n",
    "    try:\n",
    "        if not is_single_class(y_true):\n",
    "            auc = roc_auc_score(y_true, proba)\n",
    "            metrics[\"val_auc\"] = float(auc)\n",
    "            score = float(auc)\n",
    "        else:\n",
    "            metrics[\"val_auc\"] = np.nan\n",
    "    except Exception:\n",
    "        metrics[\"val_auc\"] = np.nan\n",
    "\n",
    "    # Fallback to Balanced Accuracy\n",
    "    try:\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        bacc = balanced_accuracy_score(y_true, pred)\n",
    "        metrics[\"val_bacc\"] = float(bacc)\n",
    "        if not np.isfinite(score):\n",
    "            score = float(bacc)\n",
    "    except Exception:\n",
    "        metrics[\"val_bacc\"] = np.nan\n",
    "\n",
    "    # Fallback to Accuracy if still NaN\n",
    "    try:\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        acc = accuracy_score(y_true, pred)\n",
    "        metrics[\"val_acc\"] = float(acc)\n",
    "        if not np.isfinite(score):\n",
    "            score = float(acc)\n",
    "    except Exception:\n",
    "        metrics[\"val_acc\"] = np.nan\n",
    "\n",
    "    if not np.isfinite(score):\n",
    "        score = -np.inf\n",
    "\n",
    "    return score, metrics\n",
    "\n",
    "def grid_search_classifier(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    param_grid: Dict[str, List[Any]] = DEFAULT_GRID_CLS\n",
    ") -> Tuple[Any, Dict[str, Any], Dict[str, float]]:\n",
    "    \"\"\"Grid search for classifier. Select by best (AUC -> BAcc -> Acc) on validation.\n",
    "       Always returns a valid model (never None), with robust fallbacks for single-class windows.\n",
    "    \"\"\"\n",
    "    best_score = -np.inf\n",
    "    best_params: Optional[Dict[str, Any]] = None\n",
    "    best_model: Optional[Any] = None\n",
    "    best_metrics: Dict[str, float] = {}\n",
    "\n",
    "    first_model: Optional[Any] = None\n",
    "    first_params: Optional[Dict[str, Any]] = None\n",
    "    first_metrics: Dict[str, float] = {}\n",
    "\n",
    "    for params in param_grid_product(param_grid):\n",
    "        model = fit_xgb_classifier(X_train, y_train, X_val, y_val, params=params)\n",
    "        if first_model is None:\n",
    "            first_model = model\n",
    "            first_params = params\n",
    "\n",
    "        proba = model.predict_proba(X_val)[:, 1] if len(X_val) > 0 else np.array([])\n",
    "        score, metrics = safe_classification_score(y_val, proba) if len(X_val) > 0 else (-np.inf, {})\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            best_metrics = metrics\n",
    "\n",
    "    if best_model is None and first_model is not None:\n",
    "        best_model = first_model\n",
    "        best_params = first_params\n",
    "        best_metrics = first_metrics\n",
    "\n",
    "    if best_model is None:\n",
    "        best_model = ConstantProbaClassifier(p=float(np.mean(y_train)))\n",
    "        best_params = {}\n",
    "        best_metrics = {}\n",
    "\n",
    "    best_metrics.setdefault(\"val_auc\", np.nan)\n",
    "    best_metrics.setdefault(\"val_bacc\", np.nan)\n",
    "    best_metrics.setdefault(\"val_acc\", np.nan)\n",
    "\n",
    "    return best_model, best_params, best_metrics\n",
    "\n",
    "def grid_search_regressor(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    param_grid: Dict[str, List[Any]] = DEFAULT_GRID_REG\n",
    ") -> Tuple[Any, Dict[str, Any], Dict[str, float]]:\n",
    "    \"\"\"Grid search for regressor. Select by lowest RMSE on validation. Always returns a model.\"\"\"\n",
    "    best_rmse = np.inf\n",
    "    best_params: Optional[Dict[str, Any]] = None\n",
    "    best_model: Optional[Any] = None\n",
    "\n",
    "    first_model: Optional[Any] = None\n",
    "    first_params: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    for params in param_grid_product(param_grid):\n",
    "        model = fit_xgb_regressor(X_train, y_train, X_val, y_val, params=params)\n",
    "        if first_model is None:\n",
    "            first_model = model\n",
    "            first_params = params\n",
    "        pred = model.predict(X_val) if len(X_val) > 0 else np.array([])\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, pred)) if len(X_val) > 0 else np.inf\n",
    "        if np.isfinite(rmse) and rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    if best_model is None and first_model is not None:\n",
    "        best_model = first_model\n",
    "        best_params = first_params\n",
    "        best_rmse = np.nan\n",
    "\n",
    "    if best_model is None:\n",
    "        best_model = ConstantMeanRegressor(mu=float(np.mean(y_train) if len(y_train) else 0.0))\n",
    "        best_params = {}\n",
    "        best_rmse = np.nan\n",
    "\n",
    "    return best_model, best_params, {\"val_rmse\": best_rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f08cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Fixed-window time-series CV with Grid Search\n",
    "# - For each fold:\n",
    "#   - Train on `train_window`, validate on `val_size`, test on `test_size`.\n",
    "#   - Run grid search on the training/validation split to select hyperparameters.\n",
    "#   - Evaluate on the held-out test window.\n",
    "# - We record:\n",
    "#   - Fold metrics (classification and regression),\n",
    "#   - The best params selected for the fold,\n",
    "#   - Validation scores (AUC/BalancedAcc/Acc for classifier, RMSE for regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915272e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def eval_fold(clf, reg, X_test: np.ndarray, y_cls_test: np.ndarray, y_reg_test: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate classification and regression on one fold.\"\"\"\n",
    "    proba = clf.predict_proba(X_test)[:, 1]\n",
    "    y_pred_cls = (proba >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_cls_test, y_pred_cls)\n",
    "    bacc = balanced_accuracy_score(y_cls_test, y_pred_cls)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_cls_test, proba)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "\n",
    "    y_pred_reg = reg.predict(X_test)\n",
    "    reg_mae = mean_absolute_error(y_reg_test, y_pred_reg)\n",
    "    reg_rmse = np.sqrt(mean_squared_error(y_reg_test, y_pred_reg))\n",
    "    reg_r2 = r2_score(y_reg_test, y_pred_reg)\n",
    "    dir_acc = (np.sign(y_reg_test) == np.sign(y_pred_reg)).mean()\n",
    "\n",
    "    return {\n",
    "        \"cls_acc\": acc, \"cls_bacc\": bacc, \"cls_auc\": auc,\n",
    "        \"reg_mae\": reg_mae, \"reg_rmse\": reg_rmse, \"reg_r2\": reg_r2,\n",
    "        \"reg_dir_acc\": dir_acc\n",
    "    }\n",
    "\n",
    "def fixed_window_cv_with_grid(feat_df: pd.DataFrame, feature_cols: List[str],\n",
    "                              test_size: int = 14,\n",
    "                              train_window: int = 30,\n",
    "                              val_size: int = 10,\n",
    "                              step_size: Optional[int] = None,\n",
    "                              grid_cls: Dict[str, List[Any]] = DEFAULT_GRID_CLS,\n",
    "                              grid_reg: Dict[str, List[Any]] = DEFAULT_GRID_REG) -> pd.DataFrame:\n",
    "    \"\"\"Fixed-window CV with inner grid search on the contiguous validation window.\"\"\"\n",
    "    if step_size is None:\n",
    "        step_size = test_size  # non-overlapping test windows by default\n",
    "\n",
    "    metrics: List[Dict[str, Any]] = []\n",
    "    X_all = feat_df[feature_cols].astype(float).values\n",
    "    y_cls_all = feat_df[\"target_up\"].astype(int).values\n",
    "    y_reg_all = feat_df[\"next_return\"].astype(float).values\n",
    "\n",
    "    N = len(feat_df)\n",
    "    start_index = train_window + val_size\n",
    "    fold_id = 0\n",
    "\n",
    "    for test_start in range(start_index, N - test_size + 1, step_size):\n",
    "        train_end = test_start\n",
    "        val_start = train_end - val_size\n",
    "        train_start = val_start - train_window\n",
    "        test_end = test_start + test_size\n",
    "\n",
    "        if train_start < 0:\n",
    "            continue  # not enough history\n",
    "\n",
    "        X_train = X_all[train_start: val_start]\n",
    "        y_cls_train = y_cls_all[train_start: val_start]\n",
    "        y_reg_train = y_reg_all[train_start: val_start]\n",
    "\n",
    "        X_val = X_all[val_start: train_end]\n",
    "        y_cls_val = y_cls_all[val_start: train_end]\n",
    "        y_reg_val = y_reg_all[val_start: train_end]\n",
    "\n",
    "        X_test = X_all[test_start: test_end]\n",
    "        y_cls_test = y_cls_all[test_start: test_end]\n",
    "        y_reg_test = y_reg_all[test_start: test_end]\n",
    "\n",
    "        # Grid search per fold (time-respecting, robust)\n",
    "        best_clf, best_clf_params, clf_scores = grid_search_classifier(\n",
    "            X_train, y_cls_train, X_val, y_cls_val, param_grid=grid_cls\n",
    "        )\n",
    "        best_reg, best_reg_params, reg_scores = grid_search_regressor(\n",
    "            X_train, y_reg_train, X_val, y_reg_val, param_grid=grid_reg\n",
    "        )\n",
    "\n",
    "        # Evaluate on test\n",
    "        fold_metrics = eval_fold(best_clf, best_reg, X_test, y_cls_test, y_reg_test)\n",
    "        fold_metrics[\"fold\"] = fold_id\n",
    "        fold_metrics[\"train_size\"] = len(X_train)\n",
    "        fold_metrics[\"val_size\"] = len(X_val)\n",
    "        fold_metrics[\"test_size\"] = len(X_test)\n",
    "        fold_metrics[\"test_start\"] = feat_df.index[test_start]\n",
    "        fold_metrics[\"test_end\"] = feat_df.index[test_end - 1]\n",
    "        # Store selected params and validation scores\n",
    "        fold_metrics[\"clf_params\"] = best_clf_params\n",
    "        fold_metrics[\"reg_params\"] = best_reg_params\n",
    "        fold_metrics[\"clf_val_auc\"] = clf_scores.get(\"val_auc\", np.nan)\n",
    "        fold_metrics[\"clf_val_bacc\"] = clf_scores.get(\"val_bacc\", np.nan)\n",
    "        fold_metrics[\"clf_val_acc\"] = clf_scores.get(\"val_acc\", np.nan)\n",
    "        fold_metrics[\"reg_val_rmse\"] = reg_scores.get(\"val_rmse\", np.nan)\n",
    "\n",
    "        metrics.append(fold_metrics)\n",
    "        fold_id += 1\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Run fixed-window CV with grid search\n",
    "cv_results = fixed_window_cv_with_grid(\n",
    "    feat_df, feature_cols,\n",
    "    test_size=7,\n",
    "    train_window=60,\n",
    "    val_size=10,\n",
    "    step_size=7,\n",
    "    grid_cls=DEFAULT_GRID_CLS,\n",
    "    grid_reg=DEFAULT_GRID_REG\n",
    ")\n",
    "\n",
    "print(f\"Folds: {len(cv_results)}\")\n",
    "if {\"clf_val_auc\",\"reg_val_rmse\"}.issubset(cv_results.columns):\n",
    "    display(cv_results[[\"fold\",\"test_start\",\"test_end\",\"train_size\",\"val_size\",\"test_size\",\"clf_val_auc\",\"reg_val_rmse\"]].head())\n",
    "else:\n",
    "    display(cv_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee9be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def summarize_metrics(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    return df[cols].agg(['mean','std','min','max'])\n",
    "\n",
    "print(\"\\n=== Per-fold metrics (head) ===\")\n",
    "display(cv_results.head())\n",
    "\n",
    "print(\"\\n=== Selected params (first 3 folds) ===\")\n",
    "display(cv_results[[\"fold\", \"clf_params\", \"reg_params\"]].head(3))\n",
    "\n",
    "print(\"\\n=== Summary (Classification) ===\")\n",
    "display(summarize_metrics(cv_results, [\"cls_acc\", \"cls_bacc\", \"cls_auc\"]))\n",
    "\n",
    "print(\"\\n=== Summary (Regression on next_return) ===\")\n",
    "display(summarize_metrics(cv_results, [\"reg_mae\", \"reg_rmse\", \"reg_r2\", \"reg_dir_acc\"]))\n",
    "\n",
    "# Naive baselines over the full sample\n",
    "naive_mae = feat_df[\"next_return\"].abs().mean()              # Predict 0 for regression\n",
    "naive_dir_acc = max((feat_df[\"next_return\"] > 0).mean(),     # Predict majority sign for direction\n",
    "                    (feat_df[\"next_return\"] <= 0).mean())\n",
    "\n",
    "print(\"\\n=== Naive baselines over full sample ===\")\n",
    "print(f\"Regression MAE baseline (predict 0): {naive_mae:.6f}\")\n",
    "print(f\"Direction baseline (majority sign): {naive_dir_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Visualization: predictions on the last fold\n",
    "# This section:\n",
    "# - Rebuilds the exact train/validation/test windows for the last CV fold\n",
    "#   using the dates and sizes stored in `cv_results`.\n",
    "# - Re-runs the per-fold grid search (time-respecting) to obtain the best models.\n",
    "# - Plots:\n",
    "#   1) Actual vs Predicted next_return over the test window,\n",
    "#   2) Reconstructed price paths (actual vs predicted) starting from the\n",
    "#      previous close before the test window (assuming log-returns).\n",
    "# - Prints key metrics for the last fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d43ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import r2_score  # already imported above; re-import harmless\n",
    "\n",
    "def reconstruct_price_path(start_price: float, returns: np.ndarray, assume_log_return: bool = True) -> np.ndarray:\n",
    "    \"\"\"Reconstruct price path from a starting price and a return series.\"\"\"\n",
    "    if assume_log_return:\n",
    "        path = start_price * np.exp(np.cumsum(returns))\n",
    "    else:\n",
    "        path = start_price * np.cumprod(1.0 + returns)\n",
    "    return path\n",
    "\n",
    "def plot_last_fold_predictions(feat_df: pd.DataFrame,\n",
    "                               feature_cols: list,\n",
    "                               df_raw: pd.DataFrame,\n",
    "                               cv_results: pd.DataFrame,\n",
    "                               assume_log_return: bool = True,\n",
    "                               grid_cls: dict = None,\n",
    "                               grid_reg: dict = None):\n",
    "    \"\"\"\n",
    "    Re-train best models on the last fold's train/val windows (via grid search)\n",
    "    and visualize predictions vs. actuals on the test window.\n",
    "    \"\"\"\n",
    "    if cv_results is None or len(cv_results) == 0:\n",
    "        raise ValueError(\"cv_results is empty. Run the CV first.\")\n",
    "\n",
    "    # Identify the last fold by row order\n",
    "    row = cv_results.iloc[-1]\n",
    "    test_start_date = row[\"test_start\"]\n",
    "    test_end_date = row[\"test_end\"]\n",
    "    train_size = int(row[\"train_size\"])\n",
    "    val_size = int(row[\"val_size\"])\n",
    "    test_size = int(row[\"test_size\"])\n",
    "\n",
    "    all_dates = feat_df.index\n",
    "    # Map dates back to positional indices\n",
    "    try:\n",
    "        test_start = all_dates.get_loc(test_start_date)\n",
    "        test_end = all_dates.get_loc(test_end_date) + 1  # right-open slice\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Fold dates not found in feat_df.index. Ensure cv_results matches feat_df.\")\n",
    "\n",
    "    # Recover train/val positions from sizes\n",
    "    train_end = test_start\n",
    "    val_start = train_end - val_size\n",
    "    train_start = val_start - train_size\n",
    "    if train_start < 0:\n",
    "        raise ValueError(\"Not enough history to reconstruct the last fold windows.\")\n",
    "\n",
    "    # Slice arrays for the three windows\n",
    "    X_all = feat_df[feature_cols].astype(float).values\n",
    "    y_cls_all = feat_df[\"target_up\"].astype(int).values\n",
    "    y_reg_all = feat_df[\"next_return\"].astype(float).values\n",
    "\n",
    "    X_train = X_all[train_start: val_start]\n",
    "    y_cls_train = y_cls_all[train_start: val_start]\n",
    "    y_reg_train = y_reg_all[train_start: val_start]\n",
    "\n",
    "    X_val = X_all[val_start: train_end]\n",
    "    y_cls_val = y_cls_all[val_start: train_end]\n",
    "    y_reg_val = y_reg_all[val_start: train_end]\n",
    "\n",
    "    X_test = X_all[test_start: test_end]\n",
    "    y_cls_test = y_cls_all[test_start: test_end]\n",
    "    y_reg_test = y_reg_all[test_start: test_end]\n",
    "    test_dates = all_dates[test_start: test_end]\n",
    "\n",
    "    # Run per-fold grid search again to obtain best models (time-respecting)\n",
    "    best_clf, best_clf_params, clf_scores = grid_search_classifier(\n",
    "        X_train, y_cls_train, X_val, y_cls_val,\n",
    "        param_grid=(grid_cls if grid_cls is not None else DEFAULT_GRID_CLS)\n",
    "    )\n",
    "    best_reg, best_reg_params, reg_scores = grid_search_regressor(\n",
    "        X_train, y_reg_train, X_val, y_reg_val,\n",
    "        param_grid=(grid_reg if grid_reg is not None else DEFAULT_GRID_REG)\n",
    "    )\n",
    "\n",
    "    # Predictions on the test window\n",
    "    proba = best_clf.predict_proba(X_test)[:, 1]\n",
    "    y_pred_cls = (proba >= 0.5).astype(int)\n",
    "    y_pred_reg = best_reg.predict(X_test)\n",
    "\n",
    "    # Metrics on test\n",
    "    acc = accuracy_score(y_cls_test, y_pred_cls)\n",
    "    bacc = balanced_accuracy_score(y_cls_test, y_pred_cls)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_cls_test, proba)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "\n",
    "    mae = mean_absolute_error(y_reg_test, y_pred_reg)\n",
    "    rmse = float(np.sqrt(np.mean((y_reg_test - y_pred_reg) ** 2)))\n",
    "    r2 = r2_score(y_reg_test, y_pred_reg)\n",
    "    dir_acc = float((np.sign(y_reg_test) == np.sign(y_pred_reg)).mean())\n",
    "\n",
    "    # Plot: returns and reconstructed price paths\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    ax1, ax2 = axes\n",
    "\n",
    "    # Panel 1: next_return (actual vs predicted)\n",
    "    ax1.plot(test_dates, y_reg_test, label='Actual next_return', color='tab:blue')\n",
    "    ax1.plot(test_dates, y_pred_reg, label='Predicted next_return', color='tab:orange', alpha=0.85)\n",
    "    ax1.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax1.set_title(f'Last Fold: next_return (Actual vs Predicted)\\n'\n",
    "                  f'Cls Acc={acc:.3f}, BAcc={bacc:.3f}, AUC={auc:.3f} | '\n",
    "                  f'Reg MAE={mae:.6f}, RMSE={rmse:.6f}, R2={r2:.3f}, DirAcc={dir_acc:.3f}')\n",
    "    ax1.set_ylabel('Return')\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Panel 2: reconstructed price paths (from previous close)\n",
    "    draw_price = False\n",
    "    try:\n",
    "        raw_close_aligned = df_raw.loc[feat_df.index, 'Close']\n",
    "        price_start_idx = test_start - 1\n",
    "        if price_start_idx >= 0:\n",
    "            draw_price = True\n",
    "    except Exception:\n",
    "        draw_price = False\n",
    "\n",
    "    if draw_price:\n",
    "        start_close = float(raw_close_aligned.iloc[price_start_idx])\n",
    "        actual_path = reconstruct_price_path(start_close, y_reg_test, assume_log_return=assume_log_return)\n",
    "        pred_path = reconstruct_price_path(start_close, y_pred_reg, assume_log_return=assume_log_return)\n",
    "\n",
    "        price_index = [feat_df.index[price_start_idx]] + list(test_dates)\n",
    "        ax2.plot(price_index, [start_close] + list(actual_path), label='Actual price (reconstructed)', color='tab:green')\n",
    "        ax2.plot(price_index, [start_close] + list(pred_path), label='Predicted price (reconstructed)', color='tab:red', alpha=0.85)\n",
    "        ax2.set_title('Last Fold: Reconstructed price path (from previous close)')\n",
    "        ax2.set_ylabel('Price')\n",
    "        ax2.legend(loc='best')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax2.set_visible(False)\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print key info for traceability\n",
    "    print(\"Last fold window sizes:\", f\"train={train_size}, val={val_size}, test={test_size}\")\n",
    "    print(\"Selected classifier params:\", best_clf_params)\n",
    "    print(\"Selected regressor params:\", best_reg_params)\n",
    "    print(\"Validation (from grid search) - cls:\", clf_scores, \"| reg:\", reg_scores)\n",
    "    print(\"Test metrics:\",\n",
    "          f\"Acc={acc:.3f}, BAcc={bacc:.3f}, AUC={auc:.3f} | \"\n",
    "          f\"MAE={mae:.6f}, RMSE={rmse:.6f}, R2={r2:.3f}, DirAcc={dir_acc:.3f}\")\n",
    "\n",
    "# Run the visualization for the last fold\n",
    "plot_last_fold_predictions(\n",
    "    feat_df=feat_df,\n",
    "    feature_cols=feature_cols,\n",
    "    df_raw=df_raw,\n",
    "    cv_results=cv_results,\n",
    "    assume_log_return=True  # set False if you engineered simple returns\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
