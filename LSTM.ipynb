{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ed1c1c",
   "metadata": {},
   "source": [
    "# (Legacy) LSTM.ipynb\n",
    "\n",
    "此 notebook 属于阶段性改进版本。通用代码已迁移到 `fyp_trading/`，经典策略对比请看 `strategy_*.ipynb`。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bde8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 固定窗口 LSTM（多类别）改进版：显著涨跌识别 & 策略回测\n",
    "#\n",
    "# 关键改动：\n",
    "# - **阈值选择改用 Macro-F1 / Balanced Accuracy**，避免准确率误导。\n",
    "# - **类别加权交叉熵 / 可选 Focal Loss**，缓解极度不平衡。\n",
    "# - **支持波动自适应阈值**，保证极端事件密度稳定。\n",
    "# - **交易置信阈 + 最小持有期**，减少噪声交易。\n",
    "# - 输出更丰富的诊断信息（类分布、置信阈策略表现等）。\n",
    "\n",
    "# %%\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, sys, math, random, copy\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid') if 'seaborn-v0_8-whitegrid' in plt.style.available else plt.style.use('ggplot')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 设备与随机种子\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. 参数总览\n",
    "\n",
    "# %%\n",
    "@dataclass\n",
    "class LabelingConfig:\n",
    "    use_dynamic_threshold: bool = True   # True 表示使用“k × rolling volatility”的动态阈值\n",
    "    vol_window: int = 20                 # 动态阈值的波动窗口\n",
    "    min_vol: float = 1e-4                # 阈值下限，防止过小\n",
    "    threshold_grid: Optional[np.ndarray] = None  # 阈值候选（若 None，将在运行时根据 use_dynamic_threshold 设置）\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    epochs: int = 120\n",
    "    batch_size: int = 64\n",
    "    patience: int = 15\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    lr_factor: float = 0.5\n",
    "    lr_patience: int = 8\n",
    "    lr_min: float = 1e-5\n",
    "    grad_clip: float = 1.0\n",
    "    verbose: bool = False\n",
    "\n",
    "    use_focal_loss: bool = True         # True 则使用 Focal Loss\n",
    "    focal_gamma: float = 1.0\n",
    "    use_weighted_sampler: bool = False\n",
    "    min_class_freq: int = 5              # 每个类别最少样本数要求\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StrategyConfig:\n",
    "    trade_proba_threshold: float = 0.55  # 交易置信阈\n",
    "    min_holding_period: int = 2          # 最少持有交易日（>=1）\n",
    "    transaction_cost_bp: float = 2.0     # 交易成本（基点）\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    ticker: str = \"2800.HK\"\n",
    "    period: str = \"3y\"                   # 数据区间，可按需调整\n",
    "    interval: str = \"1d\"\n",
    "    lookback: int = 50\n",
    "    train_window: int = 400\n",
    "    val_size: int = 21\n",
    "    test_size: int = 63\n",
    "    step_size: Optional[int] = 21\n",
    "    desired_macro_f1: float = 0.40       # 基准（可做报警），非硬门槛\n",
    "\n",
    "\n",
    "LABEL_CFG = LabelingConfig()\n",
    "TRAIN_CFG = TrainConfig()\n",
    "STRATEGY_CFG = StrategyConfig()\n",
    "PIPE_CFG = PipelineConfig()\n",
    "\n",
    "if LABEL_CFG.threshold_grid is None:\n",
    "    if LABEL_CFG.use_dynamic_threshold:\n",
    "        LABEL_CFG.threshold_grid = np.round(np.linspace(0.6, 1.2, 13), 3)  # k 倍波动\n",
    "    else:\n",
    "        LABEL_CFG.threshold_grid = np.round(np.linspace(0.004, 0.012, 17), 4)\n",
    "\n",
    "if PIPE_CFG.step_size is None:\n",
    "    PIPE_CFG.step_size = PIPE_CFG.test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. 数据获取\n",
    "\n",
    "# %%\n",
    "def fetch_prices(ticker: str = \"2800.HK\", period: str = \"1y\", interval: str = \"1d\") -> pd.DataFrame:\n",
    "    tk = yf.Ticker(ticker)\n",
    "    df = tk.history(period=period, interval=interval, auto_adjust=True)\n",
    "    if df is None or df.empty:\n",
    "        end = pd.Timestamp.today().normalize()\n",
    "        start = end - pd.Timedelta(days=3 * 370)\n",
    "        df = tk.history(start=start, end=end, interval=interval, auto_adjust=True)\n",
    "    if df is None or df.empty:\n",
    "        raise RuntimeError(f\"无法获取 {ticker} 数据。\")\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    return df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
    "\n",
    "df_raw = fetch_prices(ticker=PIPE_CFG.ticker, period=PIPE_CFG.period, interval=PIPE_CFG.interval)\n",
    "print(f\"数据范围: {df_raw.index.min().date()} ~ {df_raw.index.max().date()}, 共 {len(df_raw)} 根K线\")\n",
    "display(df_raw.tail())\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. 特征工程\n",
    "# %%\n",
    "def calculate_rsi(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    up = delta.clip(lower=0)\n",
    "    down = -delta.clip(upper=0)\n",
    "    roll_up = up.ewm(alpha=1 / period, adjust=False).mean()\n",
    "    roll_down = down.ewm(alpha=1 / period, adjust=False).mean().replace(0, np.nan)\n",
    "    rs = roll_up / roll_down\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "def calculate_macd(close: pd.Series, fast=12, slow=26, signal=9):\n",
    "    ema_fast = close.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = close.ewm(span=slow, adjust=False).mean()\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = macd_line.ewm(span=signal, adjust=False).mean()\n",
    "    histogram = macd_line - signal_line\n",
    "    return macd_line, signal_line, histogram\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame, horizon: int = 1, use_log_return: bool = True):\n",
    "    close = df[\"Close\"].copy()\n",
    "    feat = pd.DataFrame(index=df.index)\n",
    "\n",
    "    feat[\"ret_1d\"] = close.pct_change(1)\n",
    "    feat[\"ret_2d\"] = close.pct_change(2)\n",
    "    feat[\"ret_5d\"] = close.pct_change(5)\n",
    "    feat[\"ret_10d\"] = close.pct_change(10)\n",
    "\n",
    "    feat[\"vol_5d\"] = feat[\"ret_1d\"].rolling(5).std()\n",
    "    feat[\"vol_10d\"] = feat[\"ret_1d\"].rolling(10).std()\n",
    "    feat[\"vol_20d\"] = feat[\"ret_1d\"].rolling(20).std()\n",
    "\n",
    "    sma_5 = close.rolling(5).mean()\n",
    "    sma_10 = close.rolling(10).mean()\n",
    "    sma_20 = close.rolling(20).mean()\n",
    "    sma_50 = close.rolling(50).mean()\n",
    "\n",
    "    feat[\"close_to_sma5\"] = close.shift(1) / sma_5 - 1\n",
    "    feat[\"close_to_sma10\"] = close.shift(1) / sma_10 - 1\n",
    "    feat[\"close_to_sma20\"] = close.shift(1) / sma_20 - 1\n",
    "    feat[\"sma5_sma10\"] = sma_5 / sma_10 - 1\n",
    "    feat[\"sma10_sma20\"] = sma_10 / sma_20 - 1\n",
    "\n",
    "    feat[\"rsi_14\"] = calculate_rsi(close.shift(1), 14)\n",
    "    macd_line, signal_line, histogram = calculate_macd(close.shift(1))\n",
    "    feat[\"macd\"] = macd_line\n",
    "    feat[\"macd_signal\"] = signal_line\n",
    "    feat[\"macd_hist\"] = histogram\n",
    "\n",
    "    bb_period = 20\n",
    "    bb_std = close.rolling(bb_period).std()\n",
    "    bb_mean = close.rolling(bb_period).mean()\n",
    "    feat[\"bb_upper\"] = (bb_mean + 2 * bb_std - close.shift(1)) / close.shift(1)\n",
    "    feat[\"bb_lower\"] = (close.shift(1) - (bb_mean - 2 * bb_std)) / close.shift(1)\n",
    "\n",
    "    if \"Volume\" in df.columns:\n",
    "        vol_roll = df[\"Volume\"].rolling(20).mean().shift(1)\n",
    "        feat[\"volume_ratio\"] = (df[\"Volume\"].shift(1) / vol_roll)\n",
    "        feat[\"volume_change\"] = df[\"Volume\"].pct_change().shift(1)\n",
    "\n",
    "    feat[\"day_of_week\"] = df.index.dayofweek\n",
    "    feat[\"month\"] = df.index.month\n",
    "    feat[\"quarter\"] = df.index.quarter\n",
    "\n",
    "    for lag in [1, 2, 3, 5, 10]:\n",
    "        feat[f\"ret_lag_{lag}\"] = feat[\"ret_1d\"].shift(lag)\n",
    "\n",
    "    if use_log_return:\n",
    "        next_ret = np.log(close.shift(-horizon) / close)\n",
    "    else:\n",
    "        next_ret = close.pct_change(horizon).shift(-horizon)\n",
    "\n",
    "    feat = feat.replace([np.inf, -np.inf], np.nan)\n",
    "    data = feat.copy()\n",
    "    data[\"next_return\"] = next_ret\n",
    "\n",
    "    data = data.dropna().copy()\n",
    "    feature_cols = [c for c in data.columns if c != \"next_return\"]\n",
    "    return data, feature_cols\n",
    "\n",
    "feat_df, feature_cols = build_features(df_raw, horizon=1, use_log_return=True)\n",
    "print(f\"清洗后样本数: {len(feat_df)}, 特征数: {len(feature_cols)}\")\n",
    "display(feat_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c70a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## 4. 标签生成（支持动态阈值）\n",
    "\n",
    "# %%\n",
    "CLASS_ID_DOWN = 0\n",
    "CLASS_ID_NEUTRAL = 1\n",
    "CLASS_ID_UP = 2\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "def apply_labeling(feat_df: pd.DataFrame,\n",
    "                   base_threshold: float,\n",
    "                   label_cfg: LabelingConfig) -> pd.Series:\n",
    "    thresholds = pd.Series(base_threshold, index=feat_df.index, dtype=float)\n",
    "    if label_cfg.use_dynamic_threshold:\n",
    "        roll_vol = feat_df[\"ret_1d\"].rolling(label_cfg.vol_window).std().shift(1)\n",
    "        thresholds = (base_threshold * roll_vol).clip(lower=label_cfg.min_vol)\n",
    "    labels = pd.Series(np.nan, index=feat_df.index, dtype=float)\n",
    "    labels[feat_df[\"next_return\"] >= thresholds] = CLASS_ID_UP\n",
    "    labels[feat_df[\"next_return\"] <= -thresholds] = CLASS_ID_DOWN\n",
    "    labels[(feat_df[\"next_return\"] > -thresholds) & (feat_df[\"next_return\"] < thresholds)] = CLASS_ID_NEUTRAL\n",
    "    return labels\n",
    "\n",
    "\n",
    "def make_sequences(\n",
    "    feat_df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    lookback: int,\n",
    "    label_cols: List[str]\n",
    ") -> Tuple[np.ndarray, Dict[str, np.ndarray], pd.DatetimeIndex]:\n",
    "    X_2d = feat_df[feature_cols].astype(np.float32).values\n",
    "    dates = feat_df.index\n",
    "    N = len(feat_df)\n",
    "    if N < lookback:\n",
    "        raise ValueError(f\"样本不足: N={N} < lookback={lookback}\")\n",
    "\n",
    "    X_list = []\n",
    "    labels_dict = {col: [] for col in label_cols}\n",
    "    idx_list = []\n",
    "\n",
    "    for end in range(lookback - 1, N):\n",
    "        start = end - lookback + 1\n",
    "        X_list.append(X_2d[start:end + 1])\n",
    "        idx_list.append(dates[end])\n",
    "        for col in label_cols:\n",
    "            labels_dict[col].append(feat_df.iloc[end][col])\n",
    "\n",
    "    X_seq = np.stack(X_list).astype(np.float32)\n",
    "    labels_dict = {col: np.asarray(vals) for col, vals in labels_dict.items()}\n",
    "    seq_index = pd.DatetimeIndex(idx_list)\n",
    "    return X_seq, labels_dict, seq_index\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. 标准化工具\n",
    "\n",
    "# %%\n",
    "def fit_scaler_3d(X_train: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    assert X_train.ndim == 3\n",
    "    flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "    mean = flat.mean(axis=0)\n",
    "    std = flat.std(axis=0)\n",
    "    std = np.where(std < 1e-12, 1e-12, std)\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def transform_3d(X: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "    return (X - mean[None, None, :]) / std[None, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # ## 6. LSTM 模型与损失\n",
    "# %%\n",
    "class LSTMMultiClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int = 64, num_layers: int = 2, dropout: float = 0.4):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.act = nn.ReLU()\n",
    "        self.out = nn.Linear(hidden_size, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]\n",
    "        h = self.dropout(h)\n",
    "        h = self.act(self.fc1(h))\n",
    "        logits = self.out(h)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: Optional[torch.Tensor] = None, gamma: float = 2.0, reduction: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        ce = nn.functional.cross_entropy(logits, target, weight=self.alpha, reduction=\"none\")\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "def make_loader_classification(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    batch_size: int,\n",
    "    shuffle: bool,\n",
    "    sample_weights: Optional[np.ndarray] = None,\n",
    "    use_weighted_sampler: bool = False\n",
    ") -> DataLoader:\n",
    "    X_t = torch.from_numpy(X.astype(np.float32))\n",
    "    y_t = torch.from_numpy(y.astype(np.int64))\n",
    "    ds = TensorDataset(X_t, y_t)\n",
    "    if use_weighted_sampler and sample_weights is not None:\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=torch.from_numpy(sample_weights.astype(np.float32)),\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        return DataLoader(ds, batch_size=batch_size, sampler=sampler,\n",
    "                          num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
    "                      num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "def train_classifier(model: nn.Module,\n",
    "                     train_loader: DataLoader,\n",
    "                     val_loader: DataLoader,\n",
    "                     cfg: TrainConfig,\n",
    "                     criterion: nn.Module) -> Tuple[nn.Module, Dict[str, List[float]]]:\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "    try:\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, mode='min',\n",
    "            factor=cfg.lr_factor, patience=cfg.lr_patience,\n",
    "            min_lr=cfg.lr_min\n",
    "        )\n",
    "    except TypeError:\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, mode='min',\n",
    "            factor=cfg.lr_factor, patience=cfg.lr_patience\n",
    "        )\n",
    "\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    best_val = float('inf')\n",
    "    no_improve = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device, non_blocking=True)\n",
    "                yb = yb.to(device, non_blocking=True)\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                val_loss += loss.item() * xb.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        if cfg.verbose and (epoch % 10 == 0 or epoch == 1):\n",
    "            cur_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(f\"Epoch {epoch:03d} | train {train_loss:.6f} | val {val_loss:.6f} | lr {cur_lr:.2e}\")\n",
    "\n",
    "        if val_loss + 1e-12 < best_val:\n",
    "            best_val = val_loss\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= cfg.patience:\n",
    "                if cfg.verbose:\n",
    "                    print(f\"Early stop at epoch {epoch}, best_val={best_val:.6f}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, history\n",
    "\n",
    "def predict_logits(model: nn.Module, X: np.ndarray, batch_size: int = 256) -> np.ndarray:\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            xb = torch.from_numpy(X[i:i + batch_size].astype(np.float32)).to(device)\n",
    "            logits = model(xb)\n",
    "            outputs.append(logits.cpu().numpy())\n",
    "    return np.concatenate(outputs, axis=0)\n",
    "\n",
    "def softmax_np(logits: np.ndarray) -> np.ndarray:\n",
    "    logits = logits - logits.max(axis=1, keepdims=True)\n",
    "    exp = np.exp(logits)\n",
    "    return exp / exp.sum(axis=1, keepdims=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. 固定窗口交叉验证（多类别 + 类别权重）\n",
    "\n",
    "# %%\n",
    "def fixed_window_cv_lstm_classifier(\n",
    "    X_seq_all: np.ndarray,\n",
    "    y_all: np.ndarray,\n",
    "    returns_all: np.ndarray,\n",
    "    seq_index: pd.DatetimeIndex,\n",
    "    test_size: int,\n",
    "    train_window: int,\n",
    "    val_size: int,\n",
    "    step_size: int,\n",
    "    cfg: TrainConfig,\n",
    "    collect_predictions: bool = False,\n",
    "    verbose: bool = False,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    metrics = []\n",
    "    preds_list = []\n",
    "    N = len(X_seq_all)\n",
    "    start_index = train_window + val_size\n",
    "    fold_id = 0\n",
    "\n",
    "    for test_start in range(start_index, N - test_size + 1, step_size):\n",
    "        train_end = test_start\n",
    "        val_start = train_end - val_size\n",
    "        train_start = val_start - train_window\n",
    "        test_end = test_start + test_size\n",
    "        if train_start < 0:\n",
    "            continue\n",
    "\n",
    "        X_train = X_seq_all[train_start:val_start]\n",
    "        y_train = y_all[train_start:val_start]\n",
    "        X_val = X_seq_all[val_start:train_end]\n",
    "        y_val = y_all[val_start:train_end]\n",
    "        X_test = X_seq_all[test_start:test_end]\n",
    "        y_test = y_all[test_start:test_end]\n",
    "        r_test = returns_all[test_start:test_end]\n",
    "        test_dates = seq_index[test_start:test_end]\n",
    "\n",
    "        train_counts = np.bincount(y_train, minlength=NUM_CLASSES).astype(np.float32)\n",
    "        val_counts = np.bincount(y_val, minlength=NUM_CLASSES).astype(np.float32)\n",
    "        test_counts = np.bincount(y_test, minlength=NUM_CLASSES).astype(np.float32)\n",
    "\n",
    "        if (train_counts < cfg.min_class_freq).any():\n",
    "            if verbose:\n",
    "                print(f\"Fold {fold_id} 训练集类别不足，跳过。Counts={train_counts}\")\n",
    "            fold_id += 1\n",
    "            continue\n",
    "\n",
    "        mean, std = fit_scaler_3d(X_train)\n",
    "        X_train_sc = transform_3d(X_train, mean, std)\n",
    "        X_val_sc = transform_3d(X_val, mean, std)\n",
    "        X_test_sc = transform_3d(X_test, mean, std)\n",
    "\n",
    "        weights_per_class = train_counts.sum() / (NUM_CLASSES * np.maximum(train_counts, 1.0))\n",
    "        class_weights_tensor = torch.tensor(weights_per_class, device=device).float()\n",
    "\n",
    "        sample_weights = None\n",
    "        if cfg.use_weighted_sampler:\n",
    "            sample_weights = weights_per_class[y_train]\n",
    "\n",
    "        train_loader = make_loader_classification(\n",
    "            X_train_sc, y_train, cfg.batch_size,\n",
    "            shuffle=not cfg.use_weighted_sampler,\n",
    "            sample_weights=sample_weights,\n",
    "            use_weighted_sampler=cfg.use_weighted_sampler\n",
    "        )\n",
    "        val_loader = make_loader_classification(\n",
    "            X_val_sc, y_val, cfg.batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "        model = LSTMMultiClassifier(input_size=X_train_sc.shape[-1], hidden_size=48, dropout=0.4)\n",
    "        if cfg.use_focal_loss:\n",
    "            criterion = FocalLoss(alpha=class_weights_tensor, gamma=2.0)\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "        model, _ = train_classifier(model, train_loader, val_loader, cfg, criterion)\n",
    "\n",
    "        logits_test = predict_logits(model, X_test_sc, batch_size=256)\n",
    "        proba_test = softmax_np(logits_test)\n",
    "        y_pred = proba_test.argmax(axis=1)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        try:\n",
    "            bacc = balanced_accuracy_score(y_test, y_pred)\n",
    "        except Exception:\n",
    "            bacc = np.nan\n",
    "        macro_f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1_per_class = f1_score(y_test, y_pred, average=None, labels=[0, 1, 2], zero_division=0)\n",
    "\n",
    "        fold_metrics = {\n",
    "            \"fold\": fold_id,\n",
    "            \"acc\": acc,\n",
    "            \"bacc\": bacc,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"train_size\": len(X_train_sc),\n",
    "            \"val_size\": len(X_val_sc),\n",
    "            \"test_size\": len(X_test_sc),\n",
    "            \"test_start\": test_dates[0],\n",
    "            \"test_end\": test_dates[-1],\n",
    "            \"train_cls_0\": train_counts[0],\n",
    "            \"train_cls_1\": train_counts[1],\n",
    "            \"train_cls_2\": train_counts[2],\n",
    "            \"test_cls_0\": test_counts[0],\n",
    "            \"test_cls_1\": test_counts[1],\n",
    "            \"test_cls_2\": test_counts[2],\n",
    "            \"f1_down\": f1_per_class[0],\n",
    "            \"f1_neutral\": f1_per_class[1],\n",
    "            \"f1_up\": f1_per_class[2],\n",
    "        }\n",
    "        metrics.append(fold_metrics)\n",
    "\n",
    "        if collect_predictions:\n",
    "            fold_pred = pd.DataFrame({\n",
    "                \"fold\": fold_id,\n",
    "                \"date\": test_dates,\n",
    "                \"actual_class\": y_test,\n",
    "                \"pred_class\": y_pred,\n",
    "                \"actual_return\": r_test,\n",
    "            })\n",
    "            for cls in range(NUM_CLASSES):\n",
    "                fold_pred[f\"proba_{cls}\"] = proba_test[:, cls]\n",
    "            preds_list.append(fold_pred)\n",
    "\n",
    "        fold_id += 1\n",
    "        del model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    preds_df = pd.concat(preds_list, ignore_index=True) if (collect_predictions and preds_list) else pd.DataFrame()\n",
    "    if verbose:\n",
    "        print(f\"共生成 {len(metrics_df)} 个折。\")\n",
    "    return metrics_df, preds_df\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. 阈值搜索与选择（Macro-F1 优先）\n",
    "\n",
    "# %%\n",
    "def run_threshold_search(\n",
    "    feat_df: pd.DataFrame,\n",
    "    feature_cols: List[str],\n",
    "    lookback: int,\n",
    "    thresholds: List[float],\n",
    "    cfg: PipelineConfig,\n",
    "    train_cfg: TrainConfig,\n",
    "    label_cfg: LabelingConfig,\n",
    ") -> pd.DataFrame:\n",
    "    records = []\n",
    "    for thr in thresholds:\n",
    "        labeled_df = feat_df.copy()\n",
    "        labeled_df[\"target_class\"] = apply_labeling(labeled_df, thr, label_cfg)\n",
    "        labeled_df = labeled_df.dropna(subset=[\"target_class\"]).copy()\n",
    "        labeled_df[\"target_class\"] = labeled_df[\"target_class\"].astype(int)\n",
    "\n",
    "        class_counts = labeled_df[\"target_class\"].value_counts().reindex([0,1,2], fill_value=0)\n",
    "        if (class_counts.values < train_cfg.min_class_freq).any():\n",
    "            continue\n",
    "\n",
    "        X_seq, labels_dict, seq_index = make_sequences(\n",
    "            labeled_df,\n",
    "            feature_cols=feature_cols,\n",
    "            lookback=lookback,\n",
    "            label_cols=[\"target_class\", \"next_return\"]\n",
    "        )\n",
    "        y_all = labels_dict[\"target_class\"].astype(np.int64)\n",
    "        returns_all = labels_dict[\"next_return\"].astype(np.float32)\n",
    "\n",
    "        try:\n",
    "            cv_metrics, _ = fixed_window_cv_lstm_classifier(\n",
    "                X_seq, y_all, returns_all, seq_index,\n",
    "                test_size=cfg.test_size,\n",
    "                train_window=cfg.train_window,\n",
    "                val_size=cfg.val_size,\n",
    "                step_size=cfg.step_size,\n",
    "                cfg=train_cfg,\n",
    "                collect_predictions=False,\n",
    "                verbose=False\n",
    "            )\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        if cv_metrics.empty:\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            \"threshold\": thr,\n",
    "            \"mean_acc\": cv_metrics[\"acc\"].mean(),\n",
    "            \"std_acc\": cv_metrics[\"acc\"].std(ddof=0),\n",
    "            \"mean_bacc\": cv_metrics[\"bacc\"].mean(),\n",
    "            \"mean_macro_f1\": cv_metrics[\"macro_f1\"].mean(),\n",
    "            \"mean_f1_down\": cv_metrics[\"f1_down\"].mean(),\n",
    "            \"mean_f1_up\": cv_metrics[\"f1_up\"].mean(),\n",
    "            \"folds\": len(cv_metrics),\n",
    "            \"avg_train_cls_0\": cv_metrics[\"train_cls_0\"].mean(),\n",
    "            \"avg_train_cls_1\": cv_metrics[\"train_cls_1\"].mean(),\n",
    "            \"avg_train_cls_2\": cv_metrics[\"train_cls_2\"].mean(),\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    results_df = pd.DataFrame(records)\n",
    "    if not results_df.empty:\n",
    "        results_df = results_df.sort_values(\n",
    "            [\"mean_macro_f1\", \"mean_bacc\", \"std_acc\"],\n",
    "            ascending=[False, False, True]\n",
    "        ).reset_index(drop=True)\n",
    "    return results_df\n",
    "\n",
    "def select_best_threshold(results_df: pd.DataFrame) -> pd.Series:\n",
    "    if results_df.empty:\n",
    "        raise ValueError(\"阈值搜索无可用结果，请调整阈值范围或窗口参数。\")\n",
    "    return results_df.iloc[0]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. 分类结果汇总工具\n",
    "\n",
    "# %%\n",
    "def summarize_classification(preds_df: pd.DataFrame, class_names: List[str]) -> Dict[str, object]:\n",
    "    y_true = preds_df[\"actual_class\"].astype(int).values\n",
    "    y_pred = preds_df[\"pred_class\"].astype(int).values\n",
    "\n",
    "    overall = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    }\n",
    "    report = classification_report(\n",
    "        y_true, y_pred,\n",
    "        labels=[CLASS_ID_DOWN, CLASS_ID_NEUTRAL, CLASS_ID_UP],\n",
    "        target_names=class_names,\n",
    "        digits=3,\n",
    "        zero_division=0\n",
    "    )\n",
    "    conf = confusion_matrix(\n",
    "        y_true, y_pred,\n",
    "        labels=[CLASS_ID_DOWN, CLASS_ID_NEUTRAL, CLASS_ID_UP]\n",
    "    )\n",
    "    conf_df = pd.DataFrame(conf, index=class_names, columns=class_names)\n",
    "\n",
    "    overall[\"classification_report\"] = report\n",
    "    overall[\"confusion_matrix\"] = conf_df\n",
    "    return overall\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. 交易策略：置信阈 & 最小持有期\n",
    "\n",
    "# %%\n",
    "def generate_positions_from_proba(proba: np.ndarray,\n",
    "                                  cfg: StrategyConfig) -> np.ndarray:\n",
    "    proba_down = proba[:, CLASS_ID_DOWN]\n",
    "    proba_neutral = proba[:, CLASS_ID_NEUTRAL]\n",
    "    proba_up = proba[:, CLASS_ID_UP]\n",
    "\n",
    "    raw_signal = np.zeros(len(proba), dtype=int)\n",
    "    up_mask = (proba_up >= cfg.trade_proba_threshold) & (proba_up >= proba_down)\n",
    "    down_mask = (proba_down >= cfg.trade_proba_threshold) & (proba_down > proba_up)\n",
    "    raw_signal[up_mask] = 1\n",
    "    raw_signal[down_mask] = -1\n",
    "\n",
    "    positions = np.zeros(len(proba), dtype=int)\n",
    "    holding = 0\n",
    "    current_pos = 0\n",
    "\n",
    "    for i in range(len(proba)):\n",
    "        if holding > 0:\n",
    "            positions[i] = current_pos\n",
    "            holding -= 1\n",
    "            continue\n",
    "\n",
    "        new_signal = raw_signal[i]\n",
    "        if new_signal != 0:\n",
    "            current_pos = new_signal\n",
    "            positions[i] = current_pos\n",
    "            holding = max(cfg.min_holding_period - 1, 0)\n",
    "        else:\n",
    "            current_pos = 0\n",
    "            positions[i] = 0\n",
    "            holding = 0\n",
    "\n",
    "    return positions\n",
    "\n",
    "def simulate_significant_strategy(\n",
    "    preds_df: pd.DataFrame,\n",
    "    strategy_cfg: StrategyConfig\n",
    ") -> Tuple[pd.DataFrame, Dict[str, object]]:\n",
    "    if preds_df.empty:\n",
    "        raise ValueError(\"预测结果为空，无法回测策略。\")\n",
    "\n",
    "    df = preds_df.sort_values(\"date\").copy()\n",
    "    proba_cols = [c for c in df.columns if c.startswith(\"proba_\")]\n",
    "    proba_array = df[proba_cols].values\n",
    "    df[\"position\"] = generate_positions_from_proba(proba_array, strategy_cfg)\n",
    "\n",
    "    df[\"simple_return\"] = np.exp(df[\"actual_return\"]) - 1.0\n",
    "    df[\"strategy_simple_return\"] = df[\"position\"] * df[\"simple_return\"]\n",
    "\n",
    "    position_change = df[\"position\"].diff().abs()\n",
    "    position_change.iloc[0] = abs(df[\"position\"].iloc[0])\n",
    "    cost_rate = strategy_cfg.transaction_cost_bp / 10000.0\n",
    "    df[\"transaction_cost\"] = position_change * cost_rate\n",
    "    df[\"strategy_simple_return_after_cost\"] = df[\"strategy_simple_return\"] - df[\"transaction_cost\"]\n",
    "\n",
    "    df[\"strategy_equity\"] = (1 + df[\"strategy_simple_return_after_cost\"]).cumprod()\n",
    "    df[\"buyhold_equity\"] = (1 + df[\"simple_return\"]).cumprod()\n",
    "\n",
    "    df[\"strategy_equity\"] = df[\"strategy_equity\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"ffill\")\n",
    "    df[\"buyhold_equity\"] = df[\"buyhold_equity\"].replace([np.inf, -np.inf], np.nan).fillna(method=\"ffill\")\n",
    "\n",
    "    stats: Dict[str, object] = {}\n",
    "    total_days = len(df)\n",
    "    if total_days == 0:\n",
    "        raise ValueError(\"无交易样本。\")\n",
    "\n",
    "    strategy_final = df[\"strategy_equity\"].iloc[-1]\n",
    "    buyhold_final = df[\"buyhold_equity\"].iloc[-1]\n",
    "    stats[\"total_return\"] = strategy_final - 1\n",
    "    stats[\"buyhold_total_return\"] = buyhold_final - 1\n",
    "\n",
    "    years = max(total_days / 252, 1 / 252)\n",
    "    stats[\"annualized_return\"] = strategy_final ** (1 / years) - 1\n",
    "    stats[\"buyhold_annual_return\"] = buyhold_final ** (1 / years) - 1\n",
    "\n",
    "    daily_mean = df[\"strategy_simple_return_after_cost\"].mean()\n",
    "    daily_std = df[\"strategy_simple_return_after_cost\"].std()\n",
    "    stats[\"annualized_volatility\"] = daily_std * np.sqrt(252)\n",
    "    stats[\"sharpe_ratio\"] = (daily_mean / daily_std) * np.sqrt(252) if daily_std > 1e-8 else np.nan\n",
    "\n",
    "    cum_max = df[\"strategy_equity\"].cummax()\n",
    "    drawdown = df[\"strategy_equity\"] / cum_max - 1\n",
    "    stats[\"max_drawdown\"] = drawdown.min()\n",
    "\n",
    "    trade_mask = df[\"position\"] != 0\n",
    "    if trade_mask.any():\n",
    "        stats[\"hit_rate_on_trades\"] = (df.loc[trade_mask, \"actual_class\"] == df.loc[trade_mask, \"pred_class\"]).mean()\n",
    "        stats[\"avg_trade_return\"] = df.loc[trade_mask, \"strategy_simple_return_after_cost\"].mean()\n",
    "        stats[\"num_trading_days\"] = int(trade_mask.sum())\n",
    "    else:\n",
    "        stats[\"hit_rate_on_trades\"] = np.nan\n",
    "        stats[\"avg_trade_return\"] = np.nan\n",
    "        stats[\"num_trading_days\"] = 0\n",
    "\n",
    "    pos_dist = df[\"position\"].value_counts(normalize=True).sort_index()\n",
    "    stats[\"position_distribution\"] = {\n",
    "        \"short_pct\": pos_dist.get(-1, 0.0),\n",
    "        \"flat_pct\": pos_dist.get(0, 0.0),\n",
    "        \"long_pct\": pos_dist.get(1, 0.0),\n",
    "    }\n",
    "    stats[\"transaction_cost_bp\"] = strategy_cfg.transaction_cost_bp\n",
    "    stats[\"trade_proba_threshold\"] = strategy_cfg.trade_proba_threshold\n",
    "    stats[\"min_holding_period\"] = strategy_cfg.min_holding_period\n",
    "\n",
    "    return df, stats\n",
    "\n",
    "def plot_equity_curves(sim_df: pd.DataFrame, threshold: float, class_names: List[str], strategy_cfg: StrategyConfig):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True,\n",
    "                             gridspec_kw={\"height_ratios\": [3, 1, 1]})\n",
    "\n",
    "    ax_price = axes[0]\n",
    "    ax_pos = axes[1]\n",
    "    ax_prob = axes[2]\n",
    "\n",
    "    ax_price.plot(sim_df[\"date\"], sim_df[\"strategy_equity\"], label=\"策略权益\", color=\"tab:blue\", linewidth=2)\n",
    "    ax_price.plot(sim_df[\"date\"], sim_df[\"buyhold_equity\"], label=\"买入持有权益\", color=\"tab:orange\", linestyle=\"--\")\n",
    "    ax_price.set_ylabel(\"累计净值\")\n",
    "    ax_price.set_title(\n",
    "        f\"策略 vs 买入持有（阈值 = {threshold:.3f}，trade_thr={strategy_cfg.trade_proba_threshold:.2f}, \"\n",
    "        f\"hold≥{strategy_cfg.min_holding_period}）\"\n",
    "    )\n",
    "    ax_price.legend(loc=\"best\")\n",
    "    ax_price.grid(True, alpha=0.3)\n",
    "\n",
    "    ax_pos.step(sim_df[\"date\"], sim_df[\"position\"], where=\"post\", color=\"tab:green\", linewidth=1.5)\n",
    "    ax_pos.set_ylabel(\"仓位\")\n",
    "    ax_pos.set_yticks([-1, 0, 1])\n",
    "    ax_pos.set_yticklabels([\"做空\", \"空仓\", \"做多\"])\n",
    "    ax_pos.grid(True, alpha=0.3)\n",
    "\n",
    "    ax_prob.plot(sim_df[\"date\"], sim_df[\"proba_2\"], label=class_names[2], color=\"tab:blue\")\n",
    "    ax_prob.plot(sim_df[\"date\"], sim_df[\"proba_0\"], label=class_names[0], color=\"tab:red\")\n",
    "    ax_prob.axhline(strategy_cfg.trade_proba_threshold, color=\"gray\", linestyle=\"--\", alpha=0.6, label=\"置信阈\")\n",
    "    ax_prob.set_ylabel(\"概率\")\n",
    "    ax_prob.set_xlabel(\"日期\")\n",
    "    ax_prob.legend(loc=\"upper right\")\n",
    "    ax_prob.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. 阈值搜索\n",
    "\n",
    "# %%\n",
    "threshold_results = run_threshold_search(\n",
    "    feat_df=feat_df,\n",
    "    feature_cols=feature_cols,\n",
    "    lookback=PIPE_CFG.lookback,\n",
    "    thresholds=LABEL_CFG.threshold_grid.tolist(),\n",
    "    cfg=PIPE_CFG,\n",
    "    train_cfg=TRAIN_CFG,\n",
    "    label_cfg=LABEL_CFG\n",
    ")\n",
    "\n",
    "print(\"阈值搜索结果（按 Macro-F1/平衡准确率排序）:\")\n",
    "display(threshold_results)\n",
    "\n",
    "best_threshold_info = select_best_threshold(threshold_results)\n",
    "best_threshold = float(best_threshold_info[\"threshold\"])\n",
    "print(f\"\\n选定阈值: {best_threshold:.3f}\")\n",
    "print(best_threshold_info)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. 使用最佳阈值训练 + OOF 预测\n",
    "\n",
    "# %%\n",
    "feat_df_best = feat_df.copy()\n",
    "feat_df_best[\"target_class\"] = apply_labeling(feat_df_best, best_threshold, LABEL_CFG)\n",
    "feat_df_best = feat_df_best.dropna(subset=[\"target_class\"]).copy()\n",
    "feat_df_best[\"target_class\"] = feat_df_best[\"target_class\"].astype(int)\n",
    "\n",
    "X_seq_best, label_dict_best, seq_index_best = make_sequences(\n",
    "    feat_df_best,\n",
    "    feature_cols=feature_cols,\n",
    "    lookback=PIPE_CFG.lookback,\n",
    "    label_cols=[\"target_class\", \"next_return\"]\n",
    ")\n",
    "\n",
    "y_best = label_dict_best[\"target_class\"].astype(np.int64)\n",
    "returns_best = label_dict_best[\"next_return\"].astype(np.float32)\n",
    "\n",
    "cv_metrics, cv_preds = fixed_window_cv_lstm_classifier(\n",
    "    X_seq_best, y_best, returns_best, seq_index_best,\n",
    "    test_size=PIPE_CFG.test_size,\n",
    "    train_window=PIPE_CFG.train_window,\n",
    "    val_size=PIPE_CFG.val_size,\n",
    "    step_size=PIPE_CFG.step_size,\n",
    "    cfg=TRAIN_CFG,\n",
    "    collect_predictions=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"交叉验证折指标（前 5 行）:\")\n",
    "display(cv_metrics.head())\n",
    "\n",
    "summary_table = cv_metrics[[\"acc\", \"bacc\", \"macro_f1\", \"f1_down\", \"f1_neutral\", \"f1_up\"]].agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "print(\"\\n交叉验证指标汇总:\")\n",
    "display(summary_table)\n",
    "\n",
    "avg_macro_f1 = summary_table.loc[\"mean\", \"macro_f1\"]\n",
    "if avg_macro_f1 < PIPE_CFG.desired_macro_f1:\n",
    "    print(f\"⚠️ Macro-F1({avg_macro_f1:.3f}) 低于期望值 {PIPE_CFG.desired_macro_f1:.2f}，建议继续优化标签或模型。\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. 分类表现汇总\n",
    "\n",
    "# %%\n",
    "class_names = [\n",
    "    f\"显著下跌 (≤ -阈值)\",\n",
    "    \"无显著波动\",\n",
    "    f\"显著上涨 (≥ 阈值)\",\n",
    "]\n",
    "\n",
    "classification_summary = summarize_classification(cv_preds, class_names)\n",
    "print(\"整体准确率:\", f\"{classification_summary['accuracy']:.3f}\")\n",
    "print(\"整体平衡准确率:\", f\"{classification_summary['balanced_accuracy']:.3f}\")\n",
    "print(\"Macro-F1:\", f\"{classification_summary['macro_f1']:.3f}\")\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_summary[\"classification_report\"])\n",
    "print(\"混淆矩阵:\")\n",
    "display(classification_summary[\"confusion_matrix\"])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14. 策略回测（含置信阈 & 最小持有期）\n",
    "\n",
    "# %%\n",
    "sim_df, perf_stats = simulate_significant_strategy(\n",
    "    cv_preds,\n",
    "    strategy_cfg=STRATEGY_CFG\n",
    ")\n",
    "\n",
    "print(\"策略样本预览:\")\n",
    "display(sim_df.head())\n",
    "\n",
    "print(\"\\n策略表现指标:\")\n",
    "perf_table = pd.DataFrame([perf_stats])\n",
    "display(perf_table.T.rename(columns={0: \"值\"}))\n",
    "\n",
    "plot_equity_curves(sim_df, threshold=best_threshold, class_names=class_names, strategy_cfg=STRATEGY_CFG)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 15. 报告要点\n",
    "# - 关注 `cv_metrics` 中各折类分布，避免孤立折驱动结果。\n",
    "# - 若 Macro-F1 / F1_up / F1_down 仍低，可：\n",
    "#   - 调整 `LABEL_CFG.threshold_grid` 范围或是否使用动态阈值；\n",
    "#   - 启用 `TRAIN_CFG.use_focal_loss = True`；\n",
    "#   - 延长 `PIPE_CFG.period`、增大 `train_window`；\n",
    "#   - 调高 `STRATEGY_CFG.trade_proba_threshold` 控制噪声交易；\n",
    "#   - 引入更多外部特征或采用两阶段模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b7f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
